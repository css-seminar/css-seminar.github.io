# From universal models to local agency: opportunities for more community-controlled AI Reflection 

## Summary 
This talk focused on participatory approaches in foundation models and argued that while many AI systems claim to include stakeholder input, they often provide limited real decision-making power. This causes tension to arise between scale (foundation models) and meaningful local/domain-specific participation. Suresh encourages the public to reflect critically about the pros and cons of AI in specific use cases. She examined two case studies of AI usage in her talk: clinical care and journalism. For clinical care, she described the identity and privacy risks associated with AI usage in this setting and demonstrated why participation from intended users increases trust. With journalism, she found that people in that field were concerned over the lack of control they had over their intellectual property. In the journalism case study, she based her findings on 20 semi-structured interviews with reporters, editors, product leads, and executives. During these interviews, participants expressed mixed opinions about AI use, particularly regarding loss of control over data and fears of diminishing human voice. Overall, this talk encourages reflection on AI usage as well as more domain-specific governance models that center affected communities rather than relying on broad, generalized AI deployment.

##  Reflection
I found journalism and healthcare to be very interesting and important to gather the public’s opinion on using AI within them due to the personal nature of these settings. Many people value empathy and personal relationships/interactions in healthcare, while in journalism, unique voices and human opinions are considered essential. In healthcare, patients depend on empathy, trust, and strong interpersonal relationships when making vulnerable decisions about their well-being. In journalism, unique voices, ethical responsibility shape how the public interprets events. AI often removes human emotions from the jobs it takes over, as it can never develop a true consciousness.
My preparation helped me understand the broader governance themes of the talk, especially the tension between scale and local agency. Having previously read and been present during academic discussions related to AI policies, I was better able to understand how foundation models prioritize scalability over meaningful stakeholder input. With this background, it was easier to understand why participatory approaches can become superficial when applied to general-purpose systems. This talk emphasized that participation must involve genuine power sharing rather than simple consultation, particularly in high-stakes fields like healthcare and journalism where trust, identity, and accountability are central concerns.

## Critique

This talk focused well on the two real-world case studies that Suresh chose to examine (healthcare and journalism). I believe she raised essential questions about power, governance, and participation. I think splitting studies by domain was an effective decision because AI can affect so many different types of domains, and each one gets affected in a unique way. Suresh seemed to choose healthcare due to the private and sensitive data it contains. In journalism, the narratives shared with the public can shape how society runs and what the public values. The reporters must be aware of this and shape the narratives responsibly. She brings awareness to the highly relevant tension between scale and local agency, but she did not discuss how these studies could be generalized to be applicable to other important areas in society such as education. I also think it might have been interesting to not only discuss AI usage in healthcare with patients, but also with various types of healthcare professionals. She mentioned she conducted 20 semi-structured interviews for the journalism study, which seems like a low number to form generalized conclusions about this profession’s views on AI use.
